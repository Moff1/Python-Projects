{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012941a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c5f6a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import keras as kr\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "import autokeras as ak\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d64801ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "WorkingData = pd.read_csv(\"Dataset2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6cdfb5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CH4</th>\n",
       "      <th>SF6</th>\n",
       "      <th>HFC</th>\n",
       "      <th>PFC</th>\n",
       "      <th>NO2</th>\n",
       "      <th>CO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98903.81712</td>\n",
       "      <td>136.861720</td>\n",
       "      <td>10444.590890</td>\n",
       "      <td>303.142019</td>\n",
       "      <td>18800.57345</td>\n",
       "      <td>4.165635e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105111.44760</td>\n",
       "      <td>145.265400</td>\n",
       "      <td>9273.449152</td>\n",
       "      <td>236.002704</td>\n",
       "      <td>19626.06870</td>\n",
       "      <td>4.153397e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104363.55460</td>\n",
       "      <td>115.357167</td>\n",
       "      <td>9250.631509</td>\n",
       "      <td>202.625537</td>\n",
       "      <td>20800.03484</td>\n",
       "      <td>4.145978e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102675.20730</td>\n",
       "      <td>117.125146</td>\n",
       "      <td>9218.702440</td>\n",
       "      <td>224.924134</td>\n",
       "      <td>19083.38678</td>\n",
       "      <td>4.109685e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103029.59930</td>\n",
       "      <td>116.172156</td>\n",
       "      <td>9166.519961</td>\n",
       "      <td>171.323657</td>\n",
       "      <td>19080.91113</td>\n",
       "      <td>4.014993e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>307422.14140</td>\n",
       "      <td>12.647912</td>\n",
       "      <td>15921.050250</td>\n",
       "      <td>17965.003960</td>\n",
       "      <td>72822.53045</td>\n",
       "      <td>1.495694e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>310366.72600</td>\n",
       "      <td>11.472869</td>\n",
       "      <td>17420.516160</td>\n",
       "      <td>19484.617790</td>\n",
       "      <td>72941.49046</td>\n",
       "      <td>1.507707e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>309824.22580</td>\n",
       "      <td>11.163929</td>\n",
       "      <td>16409.641350</td>\n",
       "      <td>19481.087040</td>\n",
       "      <td>73404.72712</td>\n",
       "      <td>1.471259e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>306161.67970</td>\n",
       "      <td>10.154710</td>\n",
       "      <td>14363.665010</td>\n",
       "      <td>20912.457840</td>\n",
       "      <td>71662.09233</td>\n",
       "      <td>1.486301e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>304055.48520</td>\n",
       "      <td>17.623716</td>\n",
       "      <td>11752.197280</td>\n",
       "      <td>24255.671540</td>\n",
       "      <td>72572.95489</td>\n",
       "      <td>1.458368e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CH4         SF6           HFC           PFC          NO2  \\\n",
       "0      98903.81712  136.861720  10444.590890    303.142019  18800.57345   \n",
       "1     105111.44760  145.265400   9273.449152    236.002704  19626.06870   \n",
       "2     104363.55460  115.357167   9250.631509    202.625537  20800.03484   \n",
       "3     102675.20730  117.125146   9218.702440    224.924134  19083.38678   \n",
       "4     103029.59930  116.172156   9166.519961    171.323657  19080.91113   \n",
       "...            ...         ...           ...           ...          ...   \n",
       "1007  307422.14140   12.647912  15921.050250  17965.003960  72822.53045   \n",
       "1008  310366.72600   11.472869  17420.516160  19484.617790  72941.49046   \n",
       "1009  309824.22580   11.163929  16409.641350  19481.087040  73404.72712   \n",
       "1010  306161.67970   10.154710  14363.665010  20912.457840  71662.09233   \n",
       "1011  304055.48520   17.623716  11752.197280  24255.671540  72572.95489   \n",
       "\n",
       "               CO2  \n",
       "0     4.165635e+05  \n",
       "1     4.153397e+05  \n",
       "2     4.145978e+05  \n",
       "3     4.109685e+05  \n",
       "4     4.014993e+05  \n",
       "...            ...  \n",
       "1007  1.495694e+06  \n",
       "1008  1.507707e+06  \n",
       "1009  1.471259e+06  \n",
       "1010  1.486301e+06  \n",
       "1011  1.458368e+06  \n",
       "\n",
       "[1012 rows x 6 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WorkingData = WorkingData.iloc[: , 2:]\n",
    "WorkingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dcccc7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = WorkingData.values\n",
    "scaler = StandardScaler()\n",
    "X, Y = data[:, 0:5], data[:, 5]\n",
    "X = scaler.fit_transform(X)\n",
    "Y= Y.reshape(-1,1)\n",
    "Y = scaler.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b9f7db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b264f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = X_train.copy()\n",
    "test_features = X_test.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4711b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    r2 = 1 - SS_res/(SS_tot + K.epsilon()) \n",
    "    return 1 - (((1 - r2) * (X_train.shape[0] - 1)) / (X_train.shape[0] - X_train.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a130a526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 Complete [00h 00m 09s]\n",
      "val_loss: 0.9093396067619324\n",
      "\n",
      "Best val_loss So Far: 0.007792391814291477\n",
      "Total elapsed time: 00h 02m 51s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/40\n",
      "23/23 [==============================] - 1s 2ms/step - loss: 0.5013 - mse: 0.5013\n",
      "Epoch 2/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1782 - mse: 0.1782\n",
      "Epoch 3/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2173 - mse: 0.2173\n",
      "Epoch 4/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1377 - mse: 0.1377\n",
      "Epoch 5/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1106 - mse: 0.1106\n",
      "Epoch 6/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1637 - mse: 0.1637\n",
      "Epoch 7/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1010 - mse: 0.1010\n",
      "Epoch 8/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1191 - mse: 0.1191\n",
      "Epoch 9/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1343 - mse: 0.1343\n",
      "Epoch 10/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0781 - mse: 0.0781\n",
      "Epoch 11/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1093 - mse: 0.1093\n",
      "Epoch 12/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1697 - mse: 0.1697\n",
      "Epoch 13/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1370 - mse: 0.1370\n",
      "Epoch 14/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1006 - mse: 0.1006\n",
      "Epoch 15/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0995 - mse: 0.0995\n",
      "Epoch 16/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0799 - mse: 0.0799\n",
      "Epoch 17/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1165 - mse: 0.1165\n",
      "Epoch 18/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1034 - mse: 0.1034\n",
      "Epoch 19/40\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0818 - mse: 0.0818\n",
      "Epoch 20/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1268 - mse: 0.1268\n",
      "Epoch 21/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1137 - mse: 0.1137\n",
      "Epoch 22/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1232 - mse: 0.1232\n",
      "Epoch 23/40\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1378 - mse: 0.1378\n",
      "Epoch 24/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0738 - mse: 0.0738\n",
      "Epoch 25/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0656 - mse: 0.0656\n",
      "Epoch 26/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1435 - mse: 0.1435\n",
      "Epoch 27/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0991 - mse: 0.0991\n",
      "Epoch 28/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0845 - mse: 0.0845\n",
      "Epoch 29/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0791 - mse: 0.0791\n",
      "Epoch 30/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0788 - mse: 0.0788\n",
      "Epoch 31/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0770 - mse: 0.0770\n",
      "Epoch 32/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1013 - mse: 0.1013\n",
      "Epoch 33/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1141 - mse: 0.1141\n",
      "Epoch 34/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0711 - mse: 0.0711\n",
      "Epoch 35/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1325 - mse: 0.1325\n",
      "Epoch 36/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1207 - mse: 0.1207\n",
      "Epoch 37/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1213 - mse: 0.1213\n",
      "Epoch 38/40\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0592 - mse: 0.0592\n",
      "Epoch 39/40\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1235 - mse: 0.1235\n",
      "Epoch 40/40\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0870 - mse: 0.0870\n",
      "INFO:tensorflow:Assets written to: .\\structured_data_regressor\\best_model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x185f3bd05b0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the structured data regressor.\n",
    "reg = ak.StructuredDataRegressor(\n",
    "    overwrite=True, max_trials=25,  metrics = [\"mse\"]\n",
    ")  # It tries 3 different models.\n",
    "# Feed the structured data regressor with training data.\n",
    "reg.fit(\n",
    "    # The path to the train.csv file.\n",
    "    X_train, Y_train,\n",
    "    # The name of the label column.\n",
    "   \n",
    "    epochs=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7df358df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0157\n",
      "[0.015694325789809227, 0.015694325789809227]\n",
      "0.9827871265126661\n",
      "0.9824983199105296\n"
     ]
    }
   ],
   "source": [
    "# Predict with the best model.\n",
    "predicted_y = reg.predict(X_test)\n",
    "# Evaluate the best model with testing data.\n",
    "print(reg.evaluate(X_test,Y_test))\n",
    "r2 = 1 - .0157 / np.var(Y_test)\n",
    "print(r2)\n",
    "n = X_test.shape[0]\n",
    "k = X_test.shape[1]\n",
    "adjr2 = 1 - (((1 - r2) * (n - 1)) / (n - k - 1))\n",
    "print(adjr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5b3be5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5)]               0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 5)                0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 5)                11        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                192       \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " regression_head_1 (Dense)   (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,348\n",
      "Trainable params: 2,337\n",
      "Non-trainable params: 11\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ak_model = reg.export_model()\n",
    "ak_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c25732cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1944 - mse: 0.4731 - coeff_determination: 0.5783\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "      \n",
    "      Dense(64, activation='tanh'),\n",
    "      Dense(64, activation='tanh'),\n",
    "      Dense(64, activation='tanh'),\n",
    "      Dense(1, activation = \"tanh\")\n",
    "  ])\n",
    "\n",
    "model.compile(loss='mean_absolute_error',\n",
    "                optimizer = tf.keras.optimizers.Adam(0.001),\n",
    "                metrics = ['mse', coeff_determination])\n",
    "model.fit(X_train,Y_train,batch_size=32, epochs = 100, verbose = 0)\n",
    "model.evaluate(X_test, Y_test)\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, Y):\n",
    "    model = Sequential([\n",
    "          \n",
    "          Dense(64, activation='tanh'),\n",
    "          Dense(64, activation='tanh'),\n",
    "          Dense(64, activation='tanh'),\n",
    "          Dense(1, activation = \"tanh\")\n",
    "      ])\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                    optimizer = tf.keras.optimizers.Adam(0.001),\n",
    "                    metrics = ['mse', coeff_determination])\n",
    "    model.fit(X[train], Y[train], epochs=100, batch_size=32, verbose=0)\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ae3d546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3193 - mse: 0.7882 - coeff_determination: 0.3235\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3193 - mse: 0.7882 - coeff_determination: 0.3235\n",
      "[1]\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4253 - mse: 1.2906 - coeff_determination: -0.2078\n",
      "[2]\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4228 - mse: 1.2872 - coeff_determination: -0.1891\n",
      "[3]\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2478 - mse: 0.6545 - coeff_determination: 0.5562\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2478 - mse: 0.6545 - coeff_determination: 0.5562\n",
      "[4]\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2696 - mse: 0.6809 - coeff_determination: 0.4659\n",
      "[3 0]\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2316 - mse: 0.6400 - coeff_determination: 0.6033\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2316 - mse: 0.6400 - coeff_determination: 0.6033\n",
      "[3 1]\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2491 - mse: 0.6558 - coeff_determination: 0.5547\n",
      "[3 2]\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2403 - mse: 0.6514 - coeff_determination: 0.5702\n",
      "[3 4]\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2425 - mse: 0.6500 - coeff_determination: 0.5572\n",
      "[3 0 1]\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2332 - mse: 0.6397 - coeff_determination: 0.6107\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2332 - mse: 0.6397 - coeff_determination: 0.6107\n",
      "[3 0 2]\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2308 - mse: 0.6336 - coeff_determination: 0.6251\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.2308 - mse: 0.6336 - coeff_determination: 0.6251\n",
      "[3 0 4]\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2259 - mse: 0.6261 - coeff_determination: 0.6278\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2259 - mse: 0.6261 - coeff_determination: 0.6278\n",
      "[3 0 4 1]\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2185 - mse: 0.6231 - coeff_determination: 0.6380\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2185 - mse: 0.6231 - coeff_determination: 0.6380\n",
      "[3 0 4 2]\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2197 - mse: 0.6214 - coeff_determination: 0.6468\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2197 - mse: 0.6214 - coeff_determination: 0.6468\n",
      "[3 0 4 2 1]\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2177 - mse: 0.6227 - coeff_determination: 0.6442\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2177 - mse: 0.6227 - coeff_determination: 0.6442\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_k = X_train.shape[1]\n",
    "n = X_train.shape[0]\n",
    "ks = list(range(1,total_k + 1))\n",
    "adjr2 = np.array([])\n",
    "cvr2 = np.array([])\n",
    "i_added_array = np.array([])\n",
    "i_not_added_array = np.array([list(range(total_k))])\n",
    "i_not_added_array = i_not_added_array.reshape(-1)\n",
    "\n",
    "\n",
    "adjr2_to_add = -1000\n",
    "i_added = -1\n",
    "\n",
    "for k in range(total_k):\n",
    "    adjr2_to_add = -1000\n",
    "    i_added = -1\n",
    "    for i in range(total_k):\n",
    "        i_this_it = np.array([])\n",
    "        if np.any(i_not_added_array == i):\n",
    "            i_this_it = np.append(i_added_array, i)\n",
    "            i_this_it = i_this_it.astype(int)\n",
    "            print(i_this_it)\n",
    "            model = Sequential([\n",
    "              Dense(64, activation = \"tanh\"),\n",
    "              Dense(64, activation = \"tanh\"),\n",
    "              Dense(64, activation = \"tanh\"),\n",
    "              Dense(1, activation = \"tanh\")\n",
    "          ])\n",
    "            model.compile(loss='mean_absolute_error',\n",
    "                optimizer = tf.keras.optimizers.Adam(0.001),\n",
    "                metrics = ['mse', coeff_determination])\n",
    "            model.fit(X_train[:,i_this_it],Y_train,batch_size=32, epochs = 100,verbose = 0)\n",
    "            if model.evaluate(X_test[:,i_this_it], Y_test)[2] * 100 > adjr2_to_add:\n",
    "                adjr2_to_add = model.evaluate(X_test[:,i_this_it], Y_test)[2] * 100\n",
    "                i_added = i\n",
    "\n",
    "    adjr2 = np.append(adjr2, adjr2_to_add )\n",
    "    i_added_array = np.append(i_added_array, i_added)\n",
    "    i_added_array = i_added_array.astype(int)\n",
    "    i_to_remove = np.array([i_added])\n",
    "    i_not_added_array = np.setdiff1d(i_not_added_array, i_added_array)\n",
    "\n",
    "    kfold = KFold(n_splits=2)\n",
    "    cvscores = []\n",
    "    for train, test in kfold.split(X, Y):\n",
    "\n",
    "        model.fit(X[train][:,i_added_array], Y[train], epochs=100, batch_size=32, verbose=0)\n",
    "        scores = model.evaluate(X[test][:,i_added_array], Y[test], verbose=0)\n",
    "        \n",
    "plt.plot(ks, adjr2, label = \"AdjR2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a94f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "      \n",
    "      Dense(64, activation = \"tanh\"),\n",
    "      Dense(1, activation = \"tanh\")\n",
    "  ])\n",
    "\n",
    "model.compile(loss='mean_absolute_error',\n",
    "                optimizer = tf.keras.optimizers.Adam(0.01),\n",
    "                metrics = ['mse', coeff_determination])\n",
    "model.fit(X_train,Y_train,batch_size=32, epochs = 100,verbose = 0)\n",
    "model.evaluate(X_test, Y_test)\n",
    "\n",
    "kfold = KFold(n_splits=10)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, Y):\n",
    "    model = Sequential([\n",
    "          \n",
    "          Dense(64, activation = \"tanh\"),\n",
    "        Dense(64, activation = \"tanh\"),\n",
    "          Dense(1, activation = \"tanh\")\n",
    "      ])\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                    optimizer = tf.keras.optimizers.Adam(0.01),\n",
    "                    metrics = ['mse', coeff_determination])\n",
    "    model.fit(X[train], Y[train], epochs=100, batch_size=32, verbose=0)\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "    cvscores.append(scores[2] * 100)\n",
    "print(\"%.2f%%\" % (np.mean(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650820c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_k = X_train.shape[1]\n",
    "n = X_train.shape[0]\n",
    "ks = list(range(1,total_k + 1))\n",
    "adjr2 = np.array([])\n",
    "cvr2 = np.array([])\n",
    "i_added_array = np.array([])\n",
    "i_not_added_array = np.array([list(range(total_k))])\n",
    "i_not_added_array = i_not_added_array.reshape(-1)\n",
    "\n",
    "\n",
    "adjr2_to_add = -1000\n",
    "cvr2_to_add = -1000\n",
    "i_added = -1\n",
    "\n",
    "for k in range(total_k):\n",
    "    adjr2_to_add = -1000\n",
    "    cvr2_to_add = -1000\n",
    "    i_added = -1\n",
    "    for i in range(total_k):\n",
    "        i_this_it = np.array([])\n",
    "        if np.any(i_not_added_array == i):\n",
    "            i_this_it = np.append(i_added_array, i)\n",
    "            i_this_it = i_this_it.astype(int)\n",
    "            print(i_this_it)\n",
    "            model = Sequential([\n",
    "              Dense(64, activation = \"tanh\"),\n",
    "              Dense(64, activation = \"tanh\"),\n",
    "              Dense(1, activation = \"tanh\")\n",
    "          ])\n",
    "            model.compile(loss='mean_absolute_error',\n",
    "                optimizer = tf.keras.optimizers.Adam(0.01),\n",
    "                metrics = ['mse', coeff_determination])\n",
    "            model.fit(X_train[:,i_this_it],Y_train,batch_size=32, epochs = 100,verbose = 0)\n",
    "            if model.evaluate(X_test[:,i_this_it], Y_test)[2] * 100 > adjr2_to_add:\n",
    "                adjr2_to_add = model.evaluate(X_test[:,i_this_it], Y_test)[2] * 100\n",
    "                i_added = i\n",
    "\n",
    "    adjr2 = np.append(adjr2, adjr2_to_add )\n",
    "    i_added_array = np.append(i_added_array, i_added)\n",
    "    i_added_array = i_added_array.astype(int)\n",
    "    i_to_remove = np.array([i_added])\n",
    "    i_not_added_array = np.setdiff1d(i_not_added_array, i_added_array)\n",
    "\n",
    "    kfold = KFold(n_splits=10)\n",
    "    cvscores = []\n",
    "    for train, test in kfold.split(X, Y):\n",
    "\n",
    "        model.fit(X[train][:,i_added_array], Y[train], epochs=100, batch_size=32, verbose=0)\n",
    "        scores = model.evaluate(X[test][:,i_added_array], Y[test], verbose=0)\n",
    "        cvscores.append(scores[2] * 100)\n",
    "    cvr2_to_add = np.mean(cvscores)\n",
    "    cvr2 = np.append(cvr2, cvr2_to_add)\n",
    "plt.plot(ks, adjr2, label = \"AdjR2\")\n",
    "plt.plot(ks, cvr2, label = \"CVR2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e93e45a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada9737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23968b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3277890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
